{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7342724,"sourceType":"datasetVersion","datasetId":4263453},{"sourceType":"datasetVersion","sourceId":7354592,"datasetId":4271385}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nimport torch.nn as nn","metadata":{"execution":{"iopub.status.busy":"2024-01-07T09:01:55.595984Z","iopub.execute_input":"2024-01-07T09:01:55.596374Z","iopub.status.idle":"2024-01-07T09:01:55.601237Z","shell.execute_reply.started":"2024-01-07T09:01:55.596328Z","shell.execute_reply":"2024-01-07T09:01:55.600238Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"file_path = \"/kaggle/input/ferdousi-text/ferdousi.txt\"\nwith open(file_path, \"r\", encoding=\"utf-8\") as file:\n    dataset = file.readlines()\nsentences = [sentence.strip() for sentence in dataset]\nsentences = sentences[2:]\ninput_sentences = sentences[:-1]\noutput_sentences = sentences[1:]","metadata":{"execution":{"iopub.status.busy":"2024-01-07T08:56:16.333109Z","iopub.execute_input":"2024-01-07T08:56:16.333894Z","iopub.status.idle":"2024-01-07T08:56:16.400229Z","shell.execute_reply.started":"2024-01-07T08:56:16.333856Z","shell.execute_reply":"2024-01-07T08:56:16.399395Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"input_train = input_sentences[:int(len(input_sentences)*0.9)]\ninput_test = input_sentences[int(len(input_sentences)*0.9):]\noutput_train = output_sentences[:int(len(output_sentences)*0.9)]\noutput_test = output_sentences[int(len(output_sentences)*0.9):]","metadata":{"execution":{"iopub.status.busy":"2024-01-07T08:56:16.401223Z","iopub.execute_input":"2024-01-07T08:56:16.401527Z","iopub.status.idle":"2024-01-07T08:56:16.417090Z","shell.execute_reply.started":"2024-01-07T08:56:16.401502Z","shell.execute_reply":"2024-01-07T08:56:16.416003Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"HooshvareLab/gpt2-fa\")\nmodel = AutoModelForCausalLM.from_pretrained(\"HooshvareLab/gpt2-fa\")","metadata":{"execution":{"iopub.status.busy":"2024-01-07T08:56:50.746741Z","iopub.execute_input":"2024-01-07T08:56:50.747131Z","iopub.status.idle":"2024-01-07T08:56:55.534232Z","shell.execute_reply.started":"2024-01-07T08:56:50.747102Z","shell.execute_reply":"2024-01-07T08:56:55.533402Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/728 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9ba601d08554d188b6e8e27238a45ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/808 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f34aef66093941be8dc4011872fa314f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.16M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c916e68828e74a5e8a65f2beeaba2462"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/875k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f809600b522e4cf8af2ed930452da143"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.75M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2bac9ef39b934eb49337cc35853e0e18"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/14.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a65d57e447e44cc68c7ebd38e0a1b6aa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/104 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3bf71691ddbf4c8380a6075ec36e7bdf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/485M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"afcd1e160dd4484082e66dd1a4b043d9"}},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.pad_token = tokenizer.eos_token\ntrain_in_tokens = tokenizer(input_train, padding=True,return_tensors=\"pt\")\ntest_in_tokens = tokenizer(input_test, padding=True,return_tensors=\"pt\")\ntrain_out_tokens = tokenizer(output_train, padding=True,return_tensors=\"pt\")\ntest_out_tokens = tokenizer(output_test, padding=True,return_tensors=\"pt\")","metadata":{"execution":{"iopub.status.busy":"2024-01-07T08:56:56.408995Z","iopub.execute_input":"2024-01-07T08:56:56.409510Z","iopub.status.idle":"2024-01-07T08:57:04.292134Z","shell.execute_reply.started":"2024-01-07T08:56:56.409476Z","shell.execute_reply":"2024-01-07T08:57:04.291192Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"#model = nn.DataParallel(model, device_ids=[0, 1])\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-01-07T09:01:59.666533Z","iopub.execute_input":"2024-01-07T09:01:59.667389Z","iopub.status.idle":"2024-01-07T09:02:00.014173Z","shell.execute_reply.started":"2024-01-07T09:01:59.667333Z","shell.execute_reply":"2024-01-07T09:02:00.013282Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"train_in_ids = train_in_tokens.input_ids\ntrain_out_ids = train_out_tokens.input_ids\ntest_in_ids = test_in_tokens.input_ids\ntest_out_ids = test_out_tokens.input_ids\n\ntrain_mask = train_in_tokens.attention_mask\ntest_mask = test_in_tokens.attention_mask","metadata":{"execution":{"iopub.status.busy":"2024-01-07T09:02:05.289641Z","iopub.execute_input":"2024-01-07T09:02:05.290032Z","iopub.status.idle":"2024-01-07T09:02:05.295632Z","shell.execute_reply.started":"2024-01-07T09:02:05.290001Z","shell.execute_reply":"2024-01-07T09:02:05.294575Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"class Dataset(Dataset):\n    def __init__(self, in_ids, mask, out_ids):\n        self.input_ids = in_ids\n        self.output_ids = out_ids\n        self.attention_mask = mask\n\n    def __len__(self):\n        return len(self.input_ids)\n\n    def __getitem__(self, idx):\n        data = [self.input_ids[idx],self.attention_mask[idx],self.output_ids[idx]]\n        return data\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-07T09:02:08.191777Z","iopub.execute_input":"2024-01-07T09:02:08.192144Z","iopub.status.idle":"2024-01-07T09:02:08.198541Z","shell.execute_reply.started":"2024-01-07T09:02:08.192115Z","shell.execute_reply":"2024-01-07T09:02:08.197491Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"train_dataset = Dataset(train_in_ids,train_mask,train_out_ids)\ntest_dataset = Dataset(test_in_ids,test_mask,test_out_ids)","metadata":{"execution":{"iopub.status.busy":"2024-01-07T09:02:09.178175Z","iopub.execute_input":"2024-01-07T09:02:09.178574Z","iopub.status.idle":"2024-01-07T09:02:09.183760Z","shell.execute_reply.started":"2024-01-07T09:02:09.178542Z","shell.execute_reply":"2024-01-07T09:02:09.182678Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=256)","metadata":{"execution":{"iopub.status.busy":"2024-01-07T09:05:20.600153Z","iopub.execute_input":"2024-01-07T09:05:20.601158Z","iopub.status.idle":"2024-01-07T09:05:20.605932Z","shell.execute_reply.started":"2024-01-07T09:05:20.601122Z","shell.execute_reply":"2024-01-07T09:05:20.604997Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\ncriterion = torch.nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2024-01-07T09:05:21.420305Z","iopub.execute_input":"2024-01-07T09:05:21.421011Z","iopub.status.idle":"2024-01-07T09:05:21.427619Z","shell.execute_reply.started":"2024-01-07T09:05:21.420977Z","shell.execute_reply":"2024-01-07T09:05:21.426563Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"num_epochs=20\nfor epoch in range(num_epochs):\n    model.train()\n    epoch_train_loss = 0.0\n    \n    for batch in train_loader:\n        in_ids,masks,out_ids = batch\n        in_ids=in_ids.to(device)\n        masks=masks.to(device)\n        out_ids=out_ids.to(device)\n        optimizer.zero_grad()\n        output = model(input_ids=in_ids, attention_mask=masks).logits\n        loss = criterion(output.view(-1, output.shape[-1]), out_ids.view(-1))\n        loss.backward()\n        optimizer.step()\n        epoch_train_loss += loss.item()\n    print(f\"Epoch {epoch+1} - Train Loss: {epoch_train_loss:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-01-07T09:05:25.235072Z","iopub.execute_input":"2024-01-07T09:05:25.235976Z","iopub.status.idle":"2024-01-07T10:09:48.970961Z","shell.execute_reply.started":"2024-01-07T09:05:25.235926Z","shell.execute_reply":"2024-01-07T10:09:48.970016Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Epoch 1 - Train Loss: 1389.2711\nEpoch 2 - Train Loss: 1346.0073\nEpoch 3 - Train Loss: 1319.7741\nEpoch 4 - Train Loss: 1295.7307\nEpoch 5 - Train Loss: 1269.5527\nEpoch 6 - Train Loss: 1239.4952\nEpoch 7 - Train Loss: 1205.5621\nEpoch 8 - Train Loss: 1165.9011\nEpoch 9 - Train Loss: 1120.8339\nEpoch 10 - Train Loss: 1070.5012\nEpoch 11 - Train Loss: 1014.8733\nEpoch 12 - Train Loss: 955.5453\nEpoch 13 - Train Loss: 896.3494\nEpoch 14 - Train Loss: 836.6134\nEpoch 15 - Train Loss: 779.5689\nEpoch 16 - Train Loss: 728.2109\nEpoch 17 - Train Loss: 681.4853\nEpoch 18 - Train Loss: 642.0668\nEpoch 19 - Train Loss: 606.8619\nEpoch 20 - Train Loss: 576.4600\n","output_type":"stream"}]},{"cell_type":"code","source":"#model = nn.DataParallel(model, device_ids=[0, 1])\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-01-07T10:31:02.935617Z","iopub.execute_input":"2024-01-07T10:31:02.936069Z","iopub.status.idle":"2024-01-07T10:31:02.945516Z","shell.execute_reply.started":"2024-01-07T10:31:02.936025Z","shell.execute_reply":"2024-01-07T10:31:02.944417Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"num_epochs=20\nfor epoch in range(num_epochs):\n    model.train()\n    epoch_train_loss = 0.0\n    \n    for batch in train_loader:\n        in_ids,masks,out_ids = batch\n        in_ids=in_ids.to(device)\n        masks=masks.to(device)\n        out_ids=out_ids.to(device)\n        optimizer.zero_grad()\n        output = model(input_ids=in_ids, attention_mask=masks).logits\n        loss = criterion(output.view(-1, output.shape[-1]), out_ids.view(-1))\n        loss.backward()\n        optimizer.step()\n        epoch_train_loss += loss.item()\n    print(f\"Epoch {epoch+1} - Train Loss: {epoch_train_loss:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-01-07T10:31:05.246891Z","iopub.execute_input":"2024-01-07T10:31:05.247261Z","iopub.status.idle":"2024-01-07T11:35:20.020298Z","shell.execute_reply.started":"2024-01-07T10:31:05.247230Z","shell.execute_reply":"2024-01-07T11:35:20.019227Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stdout","text":"Epoch 1 - Train Loss: 546.3193\nEpoch 2 - Train Loss: 521.8488\nEpoch 3 - Train Loss: 504.6226\nEpoch 4 - Train Loss: 489.8986\nEpoch 5 - Train Loss: 477.7937\nEpoch 6 - Train Loss: 465.8719\nEpoch 7 - Train Loss: 456.9904\nEpoch 8 - Train Loss: 449.2982\nEpoch 9 - Train Loss: 441.9606\nEpoch 10 - Train Loss: 434.4906\nEpoch 11 - Train Loss: 429.1909\nEpoch 12 - Train Loss: 423.1715\nEpoch 13 - Train Loss: 419.1742\nEpoch 14 - Train Loss: 414.3583\nEpoch 15 - Train Loss: 410.8976\nEpoch 16 - Train Loss: 406.1819\nEpoch 17 - Train Loss: 403.1529\nEpoch 18 - Train Loss: 399.5715\nEpoch 19 - Train Loss: 396.7303\nEpoch 20 - Train Loss: 393.9435\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(model.state_dict(), \"GP2_fine_tune.pth\")","metadata":{"execution":{"iopub.status.busy":"2024-01-07T11:41:35.749290Z","iopub.execute_input":"2024-01-07T11:41:35.749700Z","iopub.status.idle":"2024-01-07T11:41:36.864632Z","shell.execute_reply.started":"2024-01-07T11:41:35.749668Z","shell.execute_reply":"2024-01-07T11:41:36.863086Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"def test_model(model,data_loader):\n    criterion = torch.nn.CrossEntropyLoss()\n    model.eval()\n    total_loss = 0\n    with torch.no_grad():\n        for batch in data_loader:\n            in_ids,masks,out_ids = batch\n            in_ids=in_ids.to(device)\n            masks=masks.to(device)\n            out_ids=out_ids.to(device)\n            output = model(input_ids=in_ids, attention_mask=masks).logits\n            loss = criterion(output.view(-1, output.shape[-1]), out_ids.view(-1))\n            total_loss += loss.item()/256\n    return total_loss","metadata":{"execution":{"iopub.status.busy":"2024-01-07T12:59:29.524451Z","iopub.execute_input":"2024-01-07T12:59:29.524826Z","iopub.status.idle":"2024-01-07T12:59:29.531631Z","shell.execute_reply.started":"2024-01-07T12:59:29.524795Z","shell.execute_reply":"2024-01-07T12:59:29.530590Z"},"trusted":true},"execution_count":191,"outputs":[]},{"cell_type":"code","source":"evaluation_metric = test_model(model,test_loader)","metadata":{"execution":{"iopub.status.busy":"2024-01-07T12:59:30.330310Z","iopub.execute_input":"2024-01-07T12:59:30.330709Z","iopub.status.idle":"2024-01-07T12:59:38.830975Z","shell.execute_reply.started":"2024-01-07T12:59:30.330677Z","shell.execute_reply":"2024-01-07T12:59:38.830018Z"},"trusted":true},"execution_count":192,"outputs":[]},{"cell_type":"code","source":"evaluation_metric ","metadata":{"execution":{"iopub.status.busy":"2024-01-07T12:59:55.181999Z","iopub.execute_input":"2024-01-07T12:59:55.182348Z","iopub.status.idle":"2024-01-07T12:59:55.188037Z","shell.execute_reply.started":"2024-01-07T12:59:55.182322Z","shell.execute_reply":"2024-01-07T12:59:55.187187Z"},"trusted":true},"execution_count":193,"outputs":[{"execution_count":193,"output_type":"execute_result","data":{"text/plain":"1.1250864677131176"},"metadata":{}}]},{"cell_type":"code","source":"def Text_generator(input_sentence,model,tokenizer):\n    input_ids = tokenizer.encode(input_sentence, add_special_tokens=True, return_tensors=\"pt\").to(device)\n    attention_mask = input_ids.ne(tokenizer.pad_token_id).float().to(device)  # Creating attention mask\n#model = model.module\n#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    model = model.to(device)\n    with torch.no_grad():\n        output = model.generate(input_ids, attention_mask=attention_mask,  min_length=2*len(input_sentence)-4, num_return_sequences=1)\n    generated_text = output[0].tolist()\n    generated_text = generated_text[len(input_ids[0]):]  \n    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n    generated  = generated_text[len(input_sentence):len(generated_text)]\n    print(input_sentence)\n    print(generated)\n    ","metadata":{"execution":{"iopub.status.busy":"2024-01-07T13:10:32.885326Z","iopub.execute_input":"2024-01-07T13:10:32.886002Z","iopub.status.idle":"2024-01-07T13:10:32.893461Z","shell.execute_reply.started":"2024-01-07T13:10:32.885970Z","shell.execute_reply":"2024-01-07T13:10:32.892420Z"},"trusted":true},"execution_count":217,"outputs":[]},{"cell_type":"code","source":"input_sentence = \"رستم برفت تا کند جنگی سخت با سهراب\"\nText_generator(input_sentence,model,tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-01-07T12:00:16.057938Z","iopub.execute_input":"2024-01-07T12:00:16.058329Z","iopub.status.idle":"2024-01-07T12:00:16.205313Z","shell.execute_reply.started":"2024-01-07T12:00:16.058301Z","shell.execute_reply":"2024-01-07T12:00:16.204402Z"},"trusted":true},"execution_count":127,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:5 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"رستم برفت تا کند جنگی سخت با سهراب\n خاک را بوس همهاز بدی سال شدان پور\n","output_type":"stream"}]},{"cell_type":"code","source":"input_sentence = \"به خال هندویش بخشم سمرقند و بخارا را\"\nText_generator(input_sentence,model,tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-01-07T12:00:49.416067Z","iopub.execute_input":"2024-01-07T12:00:49.416815Z","iopub.status.idle":"2024-01-07T12:00:49.563008Z","shell.execute_reply.started":"2024-01-07T12:00:49.416781Z","shell.execute_reply":"2024-01-07T12:00:49.562000Z"},"trusted":true},"execution_count":130,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:5 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"به خال هندویش بخشم سمرقند و بخارا را\n کنم گاه داد جزگردان هر بخششست گاه زن\n","output_type":"stream"}]},{"cell_type":"code","source":"input_sentence = \"در جایی که عقاب تیز پرکشد \"\nText_generator(input_sentence,model,tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-01-07T12:40:54.817498Z","iopub.execute_input":"2024-01-07T12:40:54.817866Z","iopub.status.idle":"2024-01-07T12:40:54.990494Z","shell.execute_reply.started":"2024-01-07T12:40:54.817835Z","shell.execute_reply":"2024-01-07T12:40:54.989501Z"},"trusted":true},"execution_count":177,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:5 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"در جایی که عقاب تیز پرکشد \nان جایی مشک شکار بی گوهر کوهز از بدماند\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}